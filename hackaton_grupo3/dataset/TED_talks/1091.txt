Eli Pariser: cuidado con la "burbuja de filtros" en la red
A medida que las empresas de la red se esfuerzan por adaptar sus servicios (incluyendo noticias y resultados de búsqueda) a nuestros gustos personales, surge una consecuencia no deseada peligrosa: quedar atrapados en una "burbuja de filtros" que nos obstaculiza el acceso a esa información que podría desafiar o ampliar nuestra visión del mundo. Eli Pariser sostiene con determinación cómo ésto, en última instancia, es malo para nosotros y para la democracia.
A Mark Zuckerberg un periodista le preguntó sobre la redifusión de contenidos web. La pregunta era: ¿por qué es tan importante? Y Zuckerberg le contestó: "Saber que una ardilla se muere en tu jardín puede ser más relevante en este momento para tus intereses que saber que muere gente en África". Quiero hablar de cómo sería la Red si se basara en esa idea de relevancia. Crecí en una zona rural de Maine y entonces, para mí, Internet era algo muy distinto. Era una conexión con el mundo. Era algo que nos conectaba a todos. Y estaba seguro de que sería genial para la democracia y para nuestra sociedad. Pero ha cambiado la manera en la que circula la información en la red y este cambio es imperceptible. Y si no prestamos atención puede convertirse en un problema grave. Noté el cambio por primera vez en una página en la que paso mucho tiempo: Facebook. En política soy progresista (¡vaya sorpresa!) pero siempre estoy abierto a las ideas de los conservadores. Me gusta escuchar sus ideas; me gusta ver los enlaces que comparten; me gusta enterarme de algunas cosas. Por eso me sorprendió darme cuenta un día de que los conservadores habían desaparecido de las novedades de Facebook. Lo que había pasado era que Facebook estaba controlando en qué enlaces hacía clic y que se había dado cuenta de que, realmente, hacia clic con más frecuencia en los enlaces de mis amigos progresistas que en los de mis amigos conservadores. Y sin consultarme excluyó a los últimos. Desaparecieron. Pero Facebook no es la única página que hace esta edición invisible y algorítmica de la Red. Google también lo hace. Si yo realizo una búsqueda y ustedes realizan una búsqueda, incluso si lo hacemos al mismo tiempo, podríamos obtener resultados de búsqueda muy diferentes. Un ingeniero me contó que, incluso sin estar conectado, hay 57 indicios que Google tiene en cuenta -desde el tipo de computadora y explorador que se está usando, hasta la ubicación- para personalizar los resultados. Piénsenlo durante un segundo, ya no existe un Google estándar. ¿Y saben qué? Lo más gracioso es que es difícil de ver. Uno no puede ver lo diferentes que son sus búsquedas de las de los demás. Pero hace un par de semanas le pedí a un puñado de amigos que googlearan "Egipto" y que me enviaran capturas de pantalla de los resultados. Esta es la captura de pantalla de mi amigo Scott. Y esta la de mi amigo Daniel. Si las ponemos lado a lado ni siquiera tenemos que leer los enlaces para ver lo diferentes que son. Pero si leemos los enlaces es muy notable. A Daniel no le aparece nada de las protestas en Egipto en su portada de resultados de Google. En los resultados de Scott aparece mucho. Y esa era la historia del día en ese momento. Así de diferentes se están volviendo los resultados. Y no se trata sólo de Google y Facebook. Esto está arrasando la Red. Hay toda una serie de empresas que están haciendo este tipo de personalización. Yahoo News, el sitio más grande de noticias de Internet, ahora es personalizado; distintas personas obtienen distintas cosas. Huffington Post, Washington Post, New York Times todos coquetean con algún tipo de personalización. Y esto marcha muy rápido hacia un mundo en el cual Internet nos va a mostrar lo que piense que queremos ver y no necesariamente lo que tenemos que ver. Como dijo Eric Schmidt: "Va a ser muy difícil que las personas miren o consuman algo que en alguna medida no haya sido hecho a medida para ellas". Creo que esto es un problema. Si uno junta todos estos filtros, todos estos algoritmos, obtiene lo que llamo la «burbuja de filtros». La burbuja de filtros es el universo propio, personal, único, de información que uno vive en la red. Y lo que haya en la burbuja de filtros depende de quién uno es, y de lo que uno hace. Pero la cosa es que uno no decide que es lo que entra. Y, más importante aún, no vemos qué es lo que se elimina. Unos investigadores de Netflix detectaron problemas con la burbuja de filtros. Estaban mirando las listas de Netflix y notaron algo gracioso, que a muchos seguro nos ha pasado, y es que algunas películas aparecen y desaparecen de nuestras listas. Entran a la lista y desaparecen enseguida. "Iron Man" desaparece y "Esperando a Súperman" puede quedar mucho tiempo. Lo que descubrieron es que en nuestras listas de Netflix ocurren estas batallas épicas entre nuestras aspiraciones futuras y nuestro yo impulsivo del momento. Ya saben, a todos nos gustaría haber visto "Rashōmon" pero en este momento queremos ver "Ace Ventura" por cuarta vez. (Risas) Por eso la mejor edición nos da lo mejor de ambas cosas. Nos da un poco de Justin Bieber y un poco de Afganistán. Nos da algunos vegetales informativos y nos da algunos postres informativos. El desafío de estos filtros algorítmicos, de estos filtros personalizados, es que al basarse principalmente en lo que uno cliquea primero pueden alterar ese equilibrio. Y en vez de tener una dieta informativa balanceada uno termine rodeado de comida chatarra informativa. Esto sugiere que quizá hemos interpretado mal la historia de Internet. En una sociedad de la difusión -eso dice el mito fundador- en una sociedad de la difusión estaban estos porteros, los editores, que controlaban el flujo de la información. Y luego aparece Internet y arrasa con ellos y nos permite a todos nosotros conectarnos unos a otros, y eso fue genial. Pero eso no es lo que está sucediendo ahora. Lo que estamos viendo se parece más a un pasaje de antorcha entre los porteros humanos y los algorítmicos. Y el problema es que los algoritmos todavía no tienen incorporados los principios éticos que tenían los editores. Entonces, si los algoritmos nos van a seleccionar el contenido, si van a decidir qué veremos y qué no, entonces tenemos que asegurarnos de que no sólo se guían por la relevancia. Tenemos que asegurarnos de que también nos muestran cosas incómodas, estimulantes o importantes -eso hace TED- otros puntos de vista. El punto es que hemos pasado por esto antes como sociedad. No es que en 1915 los periódicos se preocuparan mucho por sus responsabilidades cívicas. Después, la gente se dio cuenta de que servían para algo muy importante. Que, de hecho, no se puede tener una democracia que funcione si los ciudadanos no acceden a un buen flujo de información. Que los periódicos eran críticos porque actuaban de filtro y entonces nace la ética periodística. No era perfecta pero con eso pudimos atravesar el siglo pasado. Y ahora es como que estamos en el 1915 de la Red. Y necesitamos que los nuevos porteros incluyan este tipo de responsabilidad en el código que están escribiendo. Sé que entre los presentes hay gente de Facebook y Google -Larry y Sergey- personas que han ayudado a construir la Red tal como es y les agradezco eso. Pero realmente necesitamos que nos aseguren que estos algoritmos contienen un sentido de la vida pública, un sentido de responsabilidad cívica. Necesitamos que nos aseguren que son suficientemente transparentes, que podemos ver cuáles son las reglas que determinan lo que pasa por nuestros filtros. Y necesitamos que nos den algún control para poder decidir qué pasa y que no pasa. Porque creo que realmente necesitamos que Internet sea eso que todos soñamos que fuera. Necesitamos que nos conecte a todos. Necesitamos que nos presente nuevas ideas, nuevas personas y distintas perspectivas. Y esto no va a ser posible si nos aísla en una Red unipersonal. Gracias. (Aplausos)
