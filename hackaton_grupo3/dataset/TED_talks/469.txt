Ed Ulbrich nos muestra como Benjamin Button obtuvo su rostro.
Ed Ulbrich, el gurú de efectos digitales de Digital Domain, nos explica la tecnología merecedora de un Oscar que le permitió a su equipo crear jóvenes y ancianas versiones digitales del rostro de Brad Pitt para la película "The Curious Case of Benjamin Button."
Estoy aquí representando a un equipo de artistas, tecnólogos y [los que se dedican al cine] que trabajaron en un proyecto fílmico impresionante durante los pasados cuatro años. Y que en el camino crearon un avance en visualización computarizada. Les quiero mostrar un clip de vídeo. Con suerte no se trabará. Y si hicimos bien nuestro trabajo, no sabrán que estuvimos involucrados. Vídeo: No se como es posible... pero parece que tienes más cabello. Benjamin Button: ¿Si te dijera que no estoy envejeciendo... si no que me estoy haciendo más joven que todos? Nací con una enfermedad. Voz: ¿Qué tipo de enfermedad? BB: Nací viejo. Hombre: Cuanto lo siento. BB: No hay necesidad. No hay nada de malo con ser viejo. Niña: ¿Estás enfermo? BB: Esuché a mamá y Tizzy [susurrar] y dijeron que yo iba a morir pronto. Pero... tal vez no. Niña: Eres diferente a todos lo que he conocido antes. BB: Hubieron muchos cambios... algunos los podías ver, otros no. Empezó a salir bello en una variedad de lugares, además de otras cosas. Me sentía bastante bien, considerando las circunstancias. Ed Ulbrich: Ese fue un clip de "The Curious Case of Benjamin Button." Muchos de ustedes, algunos ya la vieron otros han escuchado la historia, pero lo que ustedes no saben es que durante, prácticamente, la primera hora de la película el personaje principal, Benjamin Button, que Brad Pitt representó, es generado por computadora del cuello para arriba. No se usó maquillaje o fotografías de Brad sobrepuestas al cuerpo de otro actor. Nosotros creamos una cabeza humana completamente digital. Aspi que me gustaría empezar con un poco de la historia del proyecto. La película esta basada en una historia de F. Scott Fitzgerald. Se trata de un hombre que nace siendo anciano y vive su vida en sentido contrario. Esta película ha circulado Hollywood por alrededor de media centuria y por fin nos involucramos en el proyecto al principio de los 90's con Ron Howard como director. Tuvimos muchas juntas y lo consideramos muy seriamente. Pero tuvimos que tirar la toalla en ese entonces. Se consideró imposible. Estaba más allá de las posibilidades de la tecnología de ese entonces el mostrar a un hombre que rejuvenecía. La forma humana, especialmente la cabeza, ha sido considerada el Cáliz Sagrado de nuestra industria. El proyecto regreso a nosotros una década después, ahora con el director David Fincher. Fincher es un hombre interesante. David es audaz cuando se trata de tecnología, y es absolutamente tenaz. David no aceptará un "No" como respuesta. y David creía, como nosotros en la industria de los efectos visuales, que cualquier cosa es possible siempre y cuando tengas suficiente tiempo, recursos y, por supuesto, dinero. Y por eso David tenía un acercamiento interesante para la película, y nos hizo un reto. ël quería que el personaje principal fuera actuado de la cuna a la tumba por un solo actor. Resultó ser este hombre. A travesamos un proceso de eliminación y un proceso de descubrimiento con David, y descartamos, por supuesto, usar diferentes actores. Esa era una idea: que usáramos diferentes actores, y que cambiáramos de actor a actor. Incluso descartamos la idea de usar maquillaje, Nos dimos cuenta de que el maquillaje simplemente no iba a bastar, particularmente en los acercamientos. Y el maquillaje es un proceso aditivo. Tienes que hacer el rostro desde cero. Como David quería grabar muy de cerca el rostro de Brad para demostrar el envejecimiento de su personaje. Necesitaba ser un personaje muy comprensivo. Así que decidimos audicionar a una serie de gente pequeña que representarían los diferentes cuerpos de Benjamin en las diferentes etapas de su vida y que de hecho construyéramos un versión generada por computadora de la cabeza de Brad envejecida para parecerse a Benjamin, y después pegar esa cabeza al cuerpo del actor real. Sonaba genial. Claro que, este era el Cáliz Sagrado de nuestra industria, y el hecho de que este hombre fuera un icono mundial no ayudaba para nada, por que seguramente si han estado en la fila del supermercado, ya saben, vemos su rostro constantemente. Así que no hay un margen de error que sea tolerable. Dos estudios estaban involucrados. Waner Brothers y Paramount. Ambos creían que esta iba a ser una película increíble, por supuesto, pero era una propuesta de alto riesgo. Mucho dinero y muchas reputaciones estaban en juego. Y creíamos que nuestra metodología era muy sólida que podría funcionar... Pero a pesar de nuestras convicciones, ellos querían una demostración. En el 2004, nos pidieron una demostración de Benjamin. Y lo logramos en alrededor de cinco semanas. Pero usamos muchos trucos y atajos Lo que logramos fue para pasar la prueba. En un momento más les mostraré el vídeo. Esta fue la primera prueba de Benjamin Button. Y aquí, pueden ver una cabeza generada por computadora. Es bastante buena. Pegada al cuerpo de un actor. Y funciono. Lo que tranquilizó enormemente al estudio. Después de muchos años de empezar y cesar el proyecto, y después de tomar la difícil decisión, por fin se decidieron por darnos la luz verde para empezar la película. Recuerdo que cuando recibí la llamada para felicitarnos, diciendo que podíamos comenzar con la película, yo, de hecho, vomité. (Risas) Saben, esto fue bastante difícil. Así que comenzamos teniendo juntas, y cuando todos estábamos reunidos, al principio parecía ser una terapia grupal, convenciéndonos y confirmándonos unos a otros de que podíamos lograrlo. Teníamos que lograr una hora de la película con un personaje. Después de todo no es una película de efectos especiales, tenía que ser acerca de un hombre. Nos sentíamos como si estuviéramos en una especie de programa de 12 pasos. Y por supuesto, el primer paso es: admitir que tienes un problema. Y nosotros teníamos un gran problema. No sabíamos como íbamos a lograrlo. Pero sí sabíamos una cosa. Proviniendo de la industria de efectos visuales, nosotros, junto con David, creíamos que teníamos tiempo suficiente, suficientes recursos y, Dios, esperábamos tener suficiente dinero. Teníamos la pasión suficiente para desarrollar el procedimiento y la tecnología. Así que cuando uno se enfrenta ante una situación similar, por supuesto que lo tienes que analizar. Tomas el gran problema y lo separas en partes más pequeñas y atacas a estas. Así que nos teníamos que concentrar en tres áreas principales. Necesitábamos envejecer a Brad. Necesitábamos envejecerlo alrededor de 45 años. También nos teníamos que asegurar de incorporar las idiosincrasias de Brad, sus pequeños tics, sus sutilezas que lo hacen ser quien es y traducir todo eso a través de nuestro proceso para que sea visible en Benjamin en la pantalla. También necesitábamos crear un personaje que fuera funcional bajo cualquier condición de trabajo. Necesitaba poder caminar en pleno día, durante la noche, con la luz de una vela, tenía que ser creíble en acercamientos extremos, el tenía que ser capaz de dialogar, tenía que correr, tenía que sudar, tenía que poder bañarse, llorar, incluso tenía que poder vomitar. No al mismo tiempo. Pero tenía que ser capaz de hacer todo eso. Y tenía que ser creíble durante casi toda la primera hora de la película. Hicimos cerca de 325 tomas. Así que necesitábamos un sistema que permitiera a Benjamin hacer lo que todo ser humano es capaz de hacer. Y nos dimos cuenta del gran abismo que existía entre el estado actual de la tecnología de punta del 2004 y donde necesitábamos que estuviera. Así que nos enfocamos en la captura de movimeinto. Estoy seguro que muchos de ustedes han visto la captura de movimiento. La tecnología de punta de ese entonces era llamada captura de movimiento basada en marcadores. Les pondré un ejemplo. La idea básicamente es, usas un leotardo, y te ponen marcadores reflectantes en tú cuerpo, y en vez de usar cámaras, hay sensores infrarrojos alrededor de un cierto volumen, y dichos sensores siguen y registran la posición tridimensional de esos marcadores en tiempo real. Después los animadores toman la información registrada de los marcadores y la aplican a un personaje generado por computadora. Pueden ver que los personajes computarizados en la derecha están realizando el mismo movimiento que los bailarines. Pero también observamos a los números de otras películas que en ese entonces usaban marcadores faciales, y esa es la idea de poner marcadores en el rostro humano y hacer el mismo proceso. Como pueden ver, el resultado es bastante patético. Esto no es muy convincente que digamos. Y d elo que nos dimos cuenta fue que lo que necesitábamos era la información de lo que estaba pasando entre los marcadores. Necesitábamos la sutileza de la piel. Necesitábamos ver como se movía la piel sobre músculo sobre hueso. Necesitábamos ceños fruncidos, hoyuelos, arrugas y todas esas cosas. Nuestra primera revelación fue abortar por completo y alejarnos de la tecnología de ese día, el estatus quo, la tecnología de punta. Así que abandonamos la captura de movimiento. Y nos encontrábamos muy en las afueras de nuestra zona de confort, en territorio inexplorado. Así que acabamos con esta idea que finalmente llamamos "estofado tecnológico". Empezamos a buscar afuera, en otros campos y la idea era que teníamos que encontar pedazos o gemas de tecnología que provinieran de otras industrias como imagenología médica, los vídeo juegos, y re-adecuarlos. Teníamos que crear algún tipo de salsa. Y esa salsa era el código del software que habíamos escrito para que este variedad de piezas tecnológicas se fusionaran y trabajaran como una sola. Inicialmente, encontramos una investigación impresionante creada por un caballero llamado Dr. Paul Ekman al inicio de los 70's. El creía que, de hecho catalogó el rostro humano. E ideó este concepto de FACS, Sistema de Codificación de Acciones Faciales. El creía que existían 70 gestos básicos o formas del rostro humano y que dichos gestos o formas del rostro, podían crear una infinidad de combinaciones posibles de cualquier cosa que el rostro humano sea capaz de hacer. Por supuesto, estos trascendían la edad, raza, cultura y género. Esto se convirtió en la base de nuestra investigación y continuamos hacia delante. Fue después cuando nos encontramos esta increíble tecnología llamada Contour. Aquí se puede ver maquillaje fosforescente siendo aplicado a un sujeto en su rostro. Lo que en verdad estamos viendo es la creación de una superficie de captura en oposición a un marcador de captura. El sujeto se posiciona en frente de un arreglo computarizado de cámaras, y esas cámaras pueden, cuadro por cuadro, reconstruir la geometría de manera precisa de lo que el sujeto esté haciendo en el momento. Asé que, efectivamente, se obtiene información 3D en tiempo real del sujeto. Y si observan una comparación, en la izquierda, vemos lo que la información volumétrica nos da y en la derecha ven lo que los marcadores nos otorgan. Así que, claramente, nos encontrábamos en una situación substancialmente mejor para esto. Pero estos eran los primeros días de esa tecnología, y no había sido realmente puesta a prueba. Pero medimos la complejidad y la fidelidad de los datos en términos de la cantidad de polígonos. Así, en la izquierda, vemos 100,000 polígonos. Podíamos escalar a los millones de polígonos. Parecería ser infinito. Fue ahí cuando tuvimos nuestro "¡a ha!". Ese fue nuestro descubrimiento. Fue en ese momento que todos decíamos, "OK, vamos a estar bien, esto va a funcionar." El "¡a ha!" fue, ¿qué pasaría si tomásemos a Brad Pitt, y pusiéramos a Brad en este aparato, y usáramos el procesos Contour, y le ponemos este maquillaje fosforescente y lo ponemos bajo luz negra, y pudiéramos, de hecho, escanear su rostro en tiempo real haciendo los poses del FACS de Eckman? ¿Cierto? Así que, prácticamente, terminamos con una base de datos tri-dimensional de todo lo que el rostro de Brad Pitt is capaz de hacer. (Risas) De aquí, seccionamos esos gestos en pedazos y componentes más pequeños de su rosotro. Fue así que terminamos con, literalmente, miles de formas del rostro. Una base de datos entera con las posibles combinaciones que su rostro es capaz de hacer. Ahora, esto es genial, excepto que lo tenemos a una edad de 44 años. Necesitamos agregarlos otros 40 años. Trajimos a Rick Baker, y Rick es uno de los grandes gurus del maquillaje y los efectos especiales de nuestra industria. También trajimos a un caballero llamado Kazu Tsuji, Kazu Tsuji es uno de los mas grandes escultores fotorealistas de nuestos tiempos. Y le pedimos que nos hiciera una maqueta, o un busto, de Benjamin. Y, en el espíritu de "El Gran Descubrimiento" -- tenía que hacer esto -- tenía que descubrir algo. Éste es Ben a los 80. Creamos tres de estas: Allí está Ben a los 80, allí está Ben a los 70 y allí está Ben a los 60. Esto se convirtió en nuestro molde para seguir adelante. Ahora, esta es una impresión de Brad. Así que, de hecho, es anatómicamente correcto. Los ojos, la quijada, los dientes... todo esta perfectamente alineado con el hombre real. Tenemos estas maquetas escaneadas en la computadora a una resolución muy alta. Una enorme cantidad de polígonos. Ahora tenemos tres incrementos de edad de Benjamin en la computadora. Pero necesitábamos una base de datos de el haciendo más que eso. Pasamos por un proceso llamado [re-trazado]. Este es Brad haciendo una pose del FACS de Eckman. Y esta es la información obtenida de la captura, el modelo que se obtiene de eso. Y el [re-trazado] es el proceso por el cual se transporta esa información a otro modelo. Y como el modelo, el busto -- la maqueta -- de Benjamin se hizo de Brad, podíamos transportar esa información de Brad a los 44 a Brad a los 87. Ahora, teníamos nuestra base de datos 3D de todo lo que el rostro de Brad Pitt puede hacer a la edad de 87, en sus 70's y en sus 60's. Ahora teníamos que empezar el proceso de filmación. Mientras todo esto sucedia, nos encontrábamos en Nueva Orleans y otras locaciones alrededor del mundo. Filmamos a nuestros actores, los filmamos usando capuchas azules. Así que este es el caballero actuando como Benjamin. La capucha azul nos ayudó de dos maneras: una, nos permitía borrar sus cabezas de manera sencilla; y también pusimos marcadores de seguimiento sobre sus cabezas para recrear el movimiento de la cámara y el lente óptico desde set. Pero ahora necesitamos la interpretación de Brad para controlar nuestro Benjamin virtual. Después editamos la grabación que se hizo en la locación con el resto de los actores y unos seis meses después trajimos a Brad a nuestro estudio de grabación en Los Ángeles y el vio en la pantalla y su trabajo era convertirse en Benjamin. Entonces repetíamos las escenas. Él las veía una y otra vez. Lo motivamos a improvisar. Y llevó a Benjamin a lugares interesantes e inusuales que nunca consideramos que fuera a ir. Lo grabamos con cuatro cámaras de alta definición para obtener diferentes ángulos de él y después David elegiría la toma de Brad siendo Benjamin he el consideraba se acomodaba mejor a lo ya filmado con el resto del equipo. De ahí proseguimos con un proceso llamado análisis de imágenes. Ahí, como se pueden ver, la toma seleccionada. Ahora vemos, la información transportada al Ben de 87 años. Lo que es interesante de todo esto es que usamos algo llamado análisis de imágenes, que es la toma de tiempos de los diferentes componentes del rostro de Benjamin. Así podíamos escoger, digamos, su ceja izquierda. El software nos diría que, pues, en el cuadro 14 su ceja izquierda se movió de aquí a acá, y concluyó su movimiento en el cuadro 32. Así podíamos escoger numerosas posiciones del rostro para obtener información de ellas. Entonces, la salsa del estofado tecnológico del que les hablaba, esa salsa secreta era, efectivamente, el software que nos había permitido empalmar la actuación de Brad en vivo con nuestra base de datos del envejecido Benjamin, los gestos FACS que ya teníamos. De cuadro en cuadro, pudimos reconstruir una cabeza 3D que empalmar perfectamente la actuación de Brad. Así se veía la toma final en la película. Aquí pueden ver al actor. Esto es lo que llamábamos la "cabeza muerta", sin hacer referencia a Jerry Garcia. Esta es la actuación reconstruida y ahora sincronizados- De nuevo, la escena final. Fue un proceso muy largo. (Aplausos) Para la siguiente sección, avanzaré muy rápido, por que podríamos hacer toda una TEDTalk de las siguientes diapositivas. Teníamos que crear un sistema de iluminación. En realidad, una gran parte de nuestros procedimientos fue la creación de un sistema de iluminación para cada lugar en el que Benjamin tenía que aparecer para que pudiéramos poner la cabeza de Ben en cualquier escena e igualara la iluminación que usaron los demás actores en el mundo real. Creamos, también, un sistema ocular. Encontramos que el viejo adagio, "Los ojos son la ventana al alma", era absolutamente verdad. Así que la clave era mantener a todos concentrados en los ojos de Ben. Y si podían sentir el calor, sentir la humanidad, y sentir sus intenciones a través de sus ojos, entonces tendríamos éxito. Para esto una persona estuvo enfocada en el sistema ocular por casi dos años. Tuvimos que crear una boca. Trabajamos a partir de los moldes dentales de Brad. Teníamos que envejecer sus dientes. Teníamos que crear una lengua articulada que le permitiera pronunciar palabras. Se escribió todo un sistema en software para articular la lengua. Una persona estuvo dedicada a la lengua por alrededor de nueve meses. El era muy popular. El movimiento de la piel: otro gran problema. La piel tenía que ser, absolutamente, precisa, y él se encuentra en una casa para ancianos, una asilo, rodeado de otros ancianos, así que tenía que actuar exactamente igual que la de los demás. Así que, mucho trabajo sobre la piel, pueden ver como en algunos de estos casos funciona, pero en otros casos se ve mal, esto fue una prueba muy, muy, muy temprana de nuestro proceso. Hasta que, efectivamente creamos una marioneta digital que Brad Pitt podía manipular con su propio rostro. No hubo animadores involucrados para interpretar el comportamiento o mejorar la actuación. Sin embargo, si nos topamos con algo, que terminamos por llamar "el efecto Botox digital". Mientras todos estaba en proceso, Fincher siempre decía "Limaba los contornos de la actuación". Y una cosa que nuestro proceso y tecnología no podía hacer era entender la intención, la intención del actor. Así que interpreta una sonrisa como una sonrisa. No reconoce una risa irónica o una sonrisa feliz, o una sonrisa frustrada. Así que si se requirieron humanos para darle ese toque. Pero llamamos a todo ese proceso y a toda la tecnología "captura emocional", en contraste de solo la captura del movimiento. Tengan otro vistazo. BB: Esuché a mamá y Tizzy [susurrar], y dijeron que yo iba a morir pronto. Pero... tal vez no. Ed Ulbrich: Así es como se crea una cabeza digital en 18 minutos. (Aplausos) Unos cuantos datos rápidos. Tomó en realidad 155 personas y dos años, y ni siquiera hablamos de los 60 cortes de cabello digitales. Pero, ese es Benjamin. Gracias.
